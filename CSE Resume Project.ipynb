{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf52349-3294-4698-b783-ba72e43ff06d",
   "metadata": {},
   "source": [
    "# Applicant Tracking System: Resume and Job Description Matches\n",
    "\n",
    "This is an applicant tracking system, often refered to as an ATS. They are commonly used by companies and businesses of all sizes, and they serve to sort through applicant resumes and return a subset as the best possible canidates for the job. Such \n",
    "\n",
    "1. What factors are the strongest indicator of a match score?\\\n",
    "**ANS:** The factor that most strongly indicates a match score was the degree a candidate held. The second most defining factor was the skills and candidate had, and the least defining was the responsibilities a candidate had in a previous position.\n",
    "\n",
    "3. Does direct word matching between a resume and description indicate a better match, or do synonyms perform just as well?\\\n",
    "**ANS:** Direct word matching between a resume and job description does indicate a better match. Synonym don’t seem to have any particular ordering, in terms of the best or worst synonym to use.\n",
    "\n",
    "5. How do different matching methods impact scoring, and what is the best method to get the most accurate score?\\\n",
    "**ANS:** The best method was to use Spacy’s similarity function to directly compare the text listed under each category, rather than using keyword extraction to uncover a percentage. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e331f5-20f9-442c-ab65-364d4efb118c",
   "metadata": {},
   "source": [
    "## Challenge Goal\n",
    "- **New library:** Natural Language Processing: Resumes and job descriptions, by nature of their use, must be human focused and readable. But with the precedent set by companies like linkedin, indeed, and glassdoor, matches between job descriptions and resumes are needed on a much faster and larger scale, and natural language processing is especially helpful for this. Parsing out the meaning and synonyms of words is especially important for ensuring an accurate match. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc3ea93-fc61-402a-bf04-490729b600d8",
   "metadata": {},
   "source": [
    "## Collaboration and Conduct\n",
    "\n",
    "Students are expected to follow Washington state law on the [Student Conduct Code for the University of Washington](https://www.washington.edu/admin/rules/policies/WAC/478-121TOC.html). In this course, students must:\n",
    "\n",
    "- Indicate on your submission any assistance received, including materials distributed in this course.\n",
    "- Not receive, generate, or otherwise acquire any substantial portion or walkthrough to an assessment.\n",
    "- Not aid, assist, attempt, or tolerate prohibited academic conduct in others.\n",
    "\n",
    "Update the following code cell to include your name and list your sources. If you used any kind of computer technology to help prepare your assessment submission, include the queries and/or prompts. Submitted work that is not consistent with sources may be subject to the student conduct process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c5d696-2e15-4c25-9fdf-b31e535b9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name = \"Ilse Schmitz\"\n",
    "sources = [\n",
    "    'https://blog.martianlogic.com/5-facts-you-must-know-about-the-applicant-tracking-system-ats' +\n",
    "    ' - This was used to uncover how ATS systems work',\n",
    "    'https://kristenfife.medium.com/understanding-how-the-ats-reads-and-interacts-with-your-resume-401bd00b66db' +\n",
    "    ' - This was used to uncover how ATS systems work',\n",
    "\n",
    "    'https://course.spacy.io/en - Spacys interactive learning course, I used it to undertand how spacy works,' +\n",
    "    'and what the spacy library can do for me.',\n",
    "    'https://spacy.io/usage/processing-pipelines' +\n",
    "    ' - FOnd by google searching \"python spacy pipeline API documentation\", I used this resource to better' +\n",
    "    'understand how to scale my code to work faster for large datasets',\n",
    "    \n",
    "    'https://deepnote.com/app/abid/spaCy-Resume-Analysis-81ba1e4b-7fa8-45fe-ac7a-0b7bf3da7826' +\n",
    "    ' - an incredible example of a working ATS system. No code has been directly copied from the example, but its' + \n",
    "    'a fantastic tool to see how ATS sysems work, and some of the ideas about how to identify keywords and' + \n",
    "    'compute percentages has been borrowed from this example.', \n",
    "    \n",
    "    'search.ipynb - Sourced the method \"clean()\" that was provided alongside this assignment', \n",
    "    'dataframes.ipynb'\n",
    "]\n",
    "\n",
    "assert your_name != \"\", \"your_name cannot be empty\"\n",
    "assert ... not in sources, \"sources should not include the placeholder ellipsis\"\n",
    "assert len(sources) >= 6, \"must include at least 6 sources, inclusive of lectures and sections\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a9116b-b1c6-424a-a790-037dd3a8a55b",
   "metadata": {},
   "source": [
    "## Data Setting and Methods\n",
    "\n",
    "*Replace this text with a description of the data setting, any data transformations you conducted, and the methods you plan to use to answer the research questions. You may remove the code cell below if you don't need it.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17015230-171b-453f-b740-d54ab8f20b61",
   "metadata": {},
   "source": [
    "### Setting Up SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0032a573-c2ae-4495-8f0e-618276818dff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Using cached murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Using cached cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Using cached preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Using cached thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Using cached srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Using cached typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (24.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.6 MB)\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (218 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Using cached murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n",
      "Using cached preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "Using cached typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "Using cached cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: cymem, wrapt, wasabi, typing-extensions, spacy-loggers, spacy-legacy, shellingham, murmurhash, mdurl, marisa-trie, cloudpathlib, catalogue, blis, annotated-types, srsly, smart-open, pydantic-core, preshed, markdown-it-py, language-data, rich, pydantic, langcodes, typer, confection, weasel, thinc, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "Successfully installed annotated-types-0.7.0 blis-1.2.0 catalogue-2.0.10 cloudpathlib-0.21.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.12 preshed-3.0.9 pydantic-2.10.6 pydantic-core-2.27.2 rich-13.9.4 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 typer-0.15.2 typing-extensions-4.12.2 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3aa769-44b1-414f-ae85-3d3f1f22270a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afebcc79-82b1-4a64-b6be-ca3e91543395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from spacy.language import Language\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "# from spacy.pipeline import EntityRuler\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokens import Doc, Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c381262-f778-4af0-9464-a021e6d12bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79340afc-d9a3-4bc2-b907-6e905bedfdff",
   "metadata": {},
   "source": [
    "### Getting CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01162c2b-7d97-4712-84b0-af9f24763c79",
   "metadata": {},
   "source": [
    "This is a dataset containing resume and job data, as well as a match score indicating the how well suited a resume is for each job. The '﻿job_position_name' column has been renamed, due to a red dot appearing only under certain circumstances. It appears in the code, but not within the displayed markdown text. I'm unsure why this appears or what it is, but the column has been renamed to avoid potential confusion or corruption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c1ec53a-4857-480a-a63b-3fbdab571cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>career_objective</th>\n",
       "      <th>skills</th>\n",
       "      <th>educational_institution_name</th>\n",
       "      <th>degree_names</th>\n",
       "      <th>passing_years</th>\n",
       "      <th>educational_results</th>\n",
       "      <th>result_types</th>\n",
       "      <th>major_field_of_studies</th>\n",
       "      <th>professional_company_names</th>\n",
       "      <th>...</th>\n",
       "      <th>online_links</th>\n",
       "      <th>issue_dates</th>\n",
       "      <th>expiry_dates</th>\n",
       "      <th>job_position_name</th>\n",
       "      <th>educationaL_requirements</th>\n",
       "      <th>experiencere_requirement</th>\n",
       "      <th>age_requirement</th>\n",
       "      <th>responsibilities.1</th>\n",
       "      <th>skills_required</th>\n",
       "      <th>matched_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Big data analytics working and database wareho...</td>\n",
       "      <td>['Big Data', 'Hadoop', 'Hive', 'Python', 'Mapr...</td>\n",
       "      <td>['The Amity School of Engineering &amp; Technology...</td>\n",
       "      <td>['B.Tech']</td>\n",
       "      <td>['2019']</td>\n",
       "      <td>['N/A']</td>\n",
       "      <td>[None]</td>\n",
       "      <td>['Electronics']</td>\n",
       "      <td>['Coca-COla']</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Senior Software Engineer</td>\n",
       "      <td>B.Sc in Computer Science &amp; Engineering from a ...</td>\n",
       "      <td>At least 1 year</td>\n",
       "      <td></td>\n",
       "      <td>Technical Support Troubleshooting Collaboratio...</td>\n",
       "      <td></td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Fresher looking to join as a data analyst and ...</td>\n",
       "      <td>['Data Analysis', 'Data Analytics', 'Business ...</td>\n",
       "      <td>['Delhi University - Hansraj College', 'Delhi ...</td>\n",
       "      <td>['B.Sc (Maths)', 'M.Sc (Science) (Statistics)']</td>\n",
       "      <td>['2015', '2018']</td>\n",
       "      <td>['N/A', 'N/A']</td>\n",
       "      <td>['N/A', 'N/A']</td>\n",
       "      <td>['Mathematics', 'Statistics']</td>\n",
       "      <td>['BIB Consultancy']</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Machine Learning (ML) Engineer</td>\n",
       "      <td>M.Sc in Computer Science &amp; Engineering or in a...</td>\n",
       "      <td>At least 5 year(s)</td>\n",
       "      <td></td>\n",
       "      <td>Machine Learning Leadership Cross-Functional C...</td>\n",
       "      <td></td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>['Software Development', 'Machine Learning', '...</td>\n",
       "      <td>['Birla Institute of Technology (BIT), Ranchi']</td>\n",
       "      <td>['B.Tech']</td>\n",
       "      <td>['2018']</td>\n",
       "      <td>['N/A']</td>\n",
       "      <td>['N/A']</td>\n",
       "      <td>['Electronics/Telecommunication']</td>\n",
       "      <td>['Axis Bank Limited']</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Executive/ Senior Executive- Trade Marketing, ...</td>\n",
       "      <td>Master of Business Administration (MBA)</td>\n",
       "      <td>At least 3 years</td>\n",
       "      <td></td>\n",
       "      <td>Trade Marketing Executive Brand Visibility, Sa...</td>\n",
       "      <td>Brand Promotion Campaign Management Field Supe...</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>To obtain a position in a fast-paced business ...</td>\n",
       "      <td>['accounts payables', 'accounts receivables', ...</td>\n",
       "      <td>['Martinez Adult Education, Business Training ...</td>\n",
       "      <td>['Computer Applications Specialist Certificate...</td>\n",
       "      <td>['2008']</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>['Computer Applications']</td>\n",
       "      <td>['Company Name ï¼ City , State', 'Company Name...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Bachelor/Honors</td>\n",
       "      <td>1 to 3 years</td>\n",
       "      <td>Age 22 to 30 years</td>\n",
       "      <td>Apparel Sourcing Quality Garment Sourcing Reli...</td>\n",
       "      <td>Fast typing skill IELTSInternet browsing &amp; onl...</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Professional accountant with an outstanding wo...</td>\n",
       "      <td>['Analytical reasoning', 'Compliance testing k...</td>\n",
       "      <td>['Kent State University']</td>\n",
       "      <td>['Bachelor of Business Administration']</td>\n",
       "      <td>[None]</td>\n",
       "      <td>['3.84']</td>\n",
       "      <td>[None]</td>\n",
       "      <td>['Accounting']</td>\n",
       "      <td>['Company Name', 'Company Name', 'Company Name...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>['February 15, 2021']</td>\n",
       "      <td>Senior iOS Engineer</td>\n",
       "      <td>Bachelor of Science (BSc) in Computer Science</td>\n",
       "      <td>At least 4 years</td>\n",
       "      <td></td>\n",
       "      <td>iOS Lifecycle Requirement Analysis Native Fram...</td>\n",
       "      <td>iOS iOS App Developer iOS Application Developm...</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9539</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>['Mathematical modelling', 'Machine Learning',...</td>\n",
       "      <td>['Sanghvi College of Engineering']</td>\n",
       "      <td>['B.Tech']</td>\n",
       "      <td>['2019']</td>\n",
       "      <td>['N/A']</td>\n",
       "      <td>['N/A']</td>\n",
       "      <td>['N/A']</td>\n",
       "      <td>['BPM Foundation']</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bachelor of Science (BSc)</td>\n",
       "      <td>5 to 8 years</td>\n",
       "      <td></td>\n",
       "      <td>Data Platform Design Data Pipeline Development...</td>\n",
       "      <td>Azure Big Data Data Analytics ETL Tools Power ...</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9540</th>\n",
       "      <td></td>\n",
       "      <td>Expertise EDA modeler. I like to learn what my...</td>\n",
       "      <td>['Data Analysis', 'Business Analysis', 'Machin...</td>\n",
       "      <td>['KVoCT, Pune', 'KVoCT, Pune']</td>\n",
       "      <td>['B.CA', 'M.CA']</td>\n",
       "      <td>['2018', '2020']</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>['Passionate Solution']</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Executive/ Sr. Executive -IT</td>\n",
       "      <td>Bachelor of Science (BSc) in Computer Science ...</td>\n",
       "      <td>3 to 5 years</td>\n",
       "      <td>Age at most 40 years</td>\n",
       "      <td>Hardware &amp; Software Installation System Monito...</td>\n",
       "      <td></td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9541</th>\n",
       "      <td></td>\n",
       "      <td>Looking for roles related to application devel...</td>\n",
       "      <td>['Business Analyst', 'Data Analytics', 'Data C...</td>\n",
       "      <td>['PGG College Mysore']</td>\n",
       "      <td>['B.BA']</td>\n",
       "      <td>['2019']</td>\n",
       "      <td>['N/A']</td>\n",
       "      <td>['N/A']</td>\n",
       "      <td>['N/A']</td>\n",
       "      <td>['ZigSAW']</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Executive - VAT</td>\n",
       "      <td>BBA in Accounting and Finance</td>\n",
       "      <td>1 to 3 years</td>\n",
       "      <td></td>\n",
       "      <td>Mushak Forms Maintenance VAT Software &amp; MS Off...</td>\n",
       "      <td>VAT and Tax</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9542</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>['Machine Learning', 'Natural Language Process...</td>\n",
       "      <td>['Rajiv Gandhi Memorial University, Delhi']</td>\n",
       "      <td>['B.TECH']</td>\n",
       "      <td>['2020']</td>\n",
       "      <td>['N/A']</td>\n",
       "      <td>['N/A']</td>\n",
       "      <td>['Electrical']</td>\n",
       "      <td>['Zynta Labs']</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>Asst. Manager/ Manger (Administrative)</td>\n",
       "      <td>Bachelor/Honors</td>\n",
       "      <td>At least 5 years</td>\n",
       "      <td>Age at least 28 years</td>\n",
       "      <td>Administrative Support Scheduling Filing &amp; Doc...</td>\n",
       "      <td>•Administration •Health Safety and Environment...</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9543</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>['assisted living', 'interpersonal and communi...</td>\n",
       "      <td>['ARIZONA STATE UNIVERSITY']</td>\n",
       "      <td>['B.A']</td>\n",
       "      <td>['N/A']</td>\n",
       "      <td>['Cum Laude']</td>\n",
       "      <td>['N/A']</td>\n",
       "      <td>['Organizational Communication Business Manage...</td>\n",
       "      <td>['Company Name', 'Company Name', 'Company Name...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Civil Engineer</td>\n",
       "      <td>B.Sc in Civil Engineering from a reputed unive...</td>\n",
       "      <td>At least 5 years</td>\n",
       "      <td>Age at least 30 years</td>\n",
       "      <td>Design Review Coordination Proposal Preparatio...</td>\n",
       "      <td>AutoCAD ETABS Microsoft Office Suite MS Project</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9544 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     address                                   career_objective  \\\n",
       "0             Big data analytics working and database wareho...   \n",
       "1             Fresher looking to join as a data analyst and ...   \n",
       "2                                                                 \n",
       "3             To obtain a position in a fast-paced business ...   \n",
       "4             Professional accountant with an outstanding wo...   \n",
       "...      ...                                                ...   \n",
       "9539                                                              \n",
       "9540          Expertise EDA modeler. I like to learn what my...   \n",
       "9541          Looking for roles related to application devel...   \n",
       "9542                                                              \n",
       "9543                                                              \n",
       "\n",
       "                                                 skills  \\\n",
       "0     ['Big Data', 'Hadoop', 'Hive', 'Python', 'Mapr...   \n",
       "1     ['Data Analysis', 'Data Analytics', 'Business ...   \n",
       "2     ['Software Development', 'Machine Learning', '...   \n",
       "3     ['accounts payables', 'accounts receivables', ...   \n",
       "4     ['Analytical reasoning', 'Compliance testing k...   \n",
       "...                                                 ...   \n",
       "9539  ['Mathematical modelling', 'Machine Learning',...   \n",
       "9540  ['Data Analysis', 'Business Analysis', 'Machin...   \n",
       "9541  ['Business Analyst', 'Data Analytics', 'Data C...   \n",
       "9542  ['Machine Learning', 'Natural Language Process...   \n",
       "9543  ['assisted living', 'interpersonal and communi...   \n",
       "\n",
       "                           educational_institution_name  \\\n",
       "0     ['The Amity School of Engineering & Technology...   \n",
       "1     ['Delhi University - Hansraj College', 'Delhi ...   \n",
       "2       ['Birla Institute of Technology (BIT), Ranchi']   \n",
       "3     ['Martinez Adult Education, Business Training ...   \n",
       "4                             ['Kent State University']   \n",
       "...                                                 ...   \n",
       "9539                 ['Sanghvi College of Engineering']   \n",
       "9540                     ['KVoCT, Pune', 'KVoCT, Pune']   \n",
       "9541                             ['PGG College Mysore']   \n",
       "9542        ['Rajiv Gandhi Memorial University, Delhi']   \n",
       "9543                       ['ARIZONA STATE UNIVERSITY']   \n",
       "\n",
       "                                           degree_names     passing_years  \\\n",
       "0                                            ['B.Tech']          ['2019']   \n",
       "1       ['B.Sc (Maths)', 'M.Sc (Science) (Statistics)']  ['2015', '2018']   \n",
       "2                                            ['B.Tech']          ['2018']   \n",
       "3     ['Computer Applications Specialist Certificate...          ['2008']   \n",
       "4               ['Bachelor of Business Administration']            [None]   \n",
       "...                                                 ...               ...   \n",
       "9539                                         ['B.Tech']          ['2019']   \n",
       "9540                                   ['B.CA', 'M.CA']  ['2018', '2020']   \n",
       "9541                                           ['B.BA']          ['2019']   \n",
       "9542                                         ['B.TECH']          ['2020']   \n",
       "9543                                            ['B.A']           ['N/A']   \n",
       "\n",
       "     educational_results    result_types  \\\n",
       "0                ['N/A']          [None]   \n",
       "1         ['N/A', 'N/A']  ['N/A', 'N/A']   \n",
       "2                ['N/A']         ['N/A']   \n",
       "3                 [None]          [None]   \n",
       "4               ['3.84']          [None]   \n",
       "...                  ...             ...   \n",
       "9539             ['N/A']         ['N/A']   \n",
       "9540        [None, None]    [None, None]   \n",
       "9541             ['N/A']         ['N/A']   \n",
       "9542             ['N/A']         ['N/A']   \n",
       "9543       ['Cum Laude']         ['N/A']   \n",
       "\n",
       "                                 major_field_of_studies  \\\n",
       "0                                       ['Electronics']   \n",
       "1                         ['Mathematics', 'Statistics']   \n",
       "2                     ['Electronics/Telecommunication']   \n",
       "3                             ['Computer Applications']   \n",
       "4                                        ['Accounting']   \n",
       "...                                                 ...   \n",
       "9539                                            ['N/A']   \n",
       "9540                                       [None, None]   \n",
       "9541                                            ['N/A']   \n",
       "9542                                     ['Electrical']   \n",
       "9543  ['Organizational Communication Business Manage...   \n",
       "\n",
       "                             professional_company_names  ... online_links  \\\n",
       "0                                         ['Coca-COla']  ...                \n",
       "1                                   ['BIB Consultancy']  ...                \n",
       "2                                 ['Axis Bank Limited']  ...                \n",
       "3     ['Company Name ï¼ City , State', 'Company Name...  ...                \n",
       "4     ['Company Name', 'Company Name', 'Company Name...  ...       [None]   \n",
       "...                                                 ...  ...          ...   \n",
       "9539                                 ['BPM Foundation']  ...                \n",
       "9540                            ['Passionate Solution']  ...                \n",
       "9541                                         ['ZigSAW']  ...                \n",
       "9542                                     ['Zynta Labs']  ...       [None]   \n",
       "9543  ['Company Name', 'Company Name', 'Company Name...  ...                \n",
       "\n",
       "     issue_dates           expiry_dates  \\\n",
       "0                                         \n",
       "1                                         \n",
       "2                                         \n",
       "3                                         \n",
       "4         [None]  ['February 15, 2021']   \n",
       "...          ...                    ...   \n",
       "9539                                      \n",
       "9540                                      \n",
       "9541                                      \n",
       "9542      [None]                 [None]   \n",
       "9543                                      \n",
       "\n",
       "                                      job_position_name  \\\n",
       "0                              Senior Software Engineer   \n",
       "1                        Machine Learning (ML) Engineer   \n",
       "2     Executive/ Senior Executive- Trade Marketing, ...   \n",
       "3                        Business Development Executive   \n",
       "4                                   Senior iOS Engineer   \n",
       "...                                                 ...   \n",
       "9539                                      Data Engineer   \n",
       "9540                       Executive/ Sr. Executive -IT   \n",
       "9541                                    Executive - VAT   \n",
       "9542             Asst. Manager/ Manger (Administrative)   \n",
       "9543                                     Civil Engineer   \n",
       "\n",
       "                               educationaL_requirements  \\\n",
       "0     B.Sc in Computer Science & Engineering from a ...   \n",
       "1     M.Sc in Computer Science & Engineering or in a...   \n",
       "2               Master of Business Administration (MBA)   \n",
       "3                                       Bachelor/Honors   \n",
       "4         Bachelor of Science (BSc) in Computer Science   \n",
       "...                                                 ...   \n",
       "9539                          Bachelor of Science (BSc)   \n",
       "9540  Bachelor of Science (BSc) in Computer Science ...   \n",
       "9541                      BBA in Accounting and Finance   \n",
       "9542                                    Bachelor/Honors   \n",
       "9543  B.Sc in Civil Engineering from a reputed unive...   \n",
       "\n",
       "     experiencere_requirement        age_requirement  \\\n",
       "0             At least 1 year                          \n",
       "1          At least 5 year(s)                          \n",
       "2            At least 3 years                          \n",
       "3                1 to 3 years     Age 22 to 30 years   \n",
       "4            At least 4 years                          \n",
       "...                       ...                    ...   \n",
       "9539             5 to 8 years                          \n",
       "9540             3 to 5 years   Age at most 40 years   \n",
       "9541             1 to 3 years                          \n",
       "9542         At least 5 years  Age at least 28 years   \n",
       "9543         At least 5 years  Age at least 30 years   \n",
       "\n",
       "                                     responsibilities.1  \\\n",
       "0     Technical Support Troubleshooting Collaboratio...   \n",
       "1     Machine Learning Leadership Cross-Functional C...   \n",
       "2     Trade Marketing Executive Brand Visibility, Sa...   \n",
       "3     Apparel Sourcing Quality Garment Sourcing Reli...   \n",
       "4     iOS Lifecycle Requirement Analysis Native Fram...   \n",
       "...                                                 ...   \n",
       "9539  Data Platform Design Data Pipeline Development...   \n",
       "9540  Hardware & Software Installation System Monito...   \n",
       "9541  Mushak Forms Maintenance VAT Software & MS Off...   \n",
       "9542  Administrative Support Scheduling Filing & Doc...   \n",
       "9543  Design Review Coordination Proposal Preparatio...   \n",
       "\n",
       "                                        skills_required matched_score  \n",
       "0                                                            0.850000  \n",
       "1                                                            0.750000  \n",
       "2     Brand Promotion Campaign Management Field Supe...      0.416667  \n",
       "3     Fast typing skill IELTSInternet browsing & onl...      0.760000  \n",
       "4     iOS iOS App Developer iOS Application Developm...      0.650000  \n",
       "...                                                 ...           ...  \n",
       "9539  Azure Big Data Data Analytics ETL Tools Power ...      0.683333  \n",
       "9540                                                         0.650000  \n",
       "9541                                        VAT and Tax      0.650000  \n",
       "9542  •Administration •Health Safety and Environment...      0.650000  \n",
       "9543    AutoCAD ETABS Microsoft Office Suite MS Project      0.650000  \n",
       "\n",
       "[9544 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Resume Job Match Dataset\n",
    "resume_job_match = pd.read_csv('resume_data.csv') \n",
    "resume_job_match.rename(columns={'﻿job_position_name': 'job_position_name'}, inplace=True)\n",
    "resume_job_match.fillna('', inplace=True)\n",
    "cols = ['skills', 'skills_required', 'related_skils_in_job', 'responsibilities', 'responsibilities.1']\n",
    "for col in cols:\n",
    "    resume_job_match[col] =  resume_job_match[col].str.replace('\\n', ' ')\n",
    "resume_job_match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf8b2ea-c6c4-4dcd-815d-d14bc156cff4",
   "metadata": {},
   "source": [
    "### Build Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f82369a-4b1d-4c5e-aaf6-b747b453a157",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2692b0de-71c3-4d79-906a-dcfa63a27e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_docs(dataframe, disabled, col_A, col_B=None):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe, a list of strings containg the pipes to disable when creating nlp objects, and one or two | *****\n",
    "    strings containing the names of columns in the data frame.     \n",
    "    If there are two column names given, concatenate each element found in col_A and col_B element wise into a list \n",
    "    of the same length as the dataframe.\n",
    "    Otherwise, transform the column col_A from the dataframe into a list. \n",
    "    Transform each list item into a generator of Doc items.\n",
    "    Return the generator.\n",
    "    \"\"\"\n",
    "    if col_B is None:\n",
    "        col_data = dataframe[col_A].tolist()\n",
    "    else:\n",
    "        col_data = (dataframe[col_A] + dataframe[col_B]).tolist()\n",
    "    docs = nlp.pipe(col_data, disable=disabled)\n",
    "    return docs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fb4696c-9e5a-4781-9f19-c4c577a85232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_similarity(data, job_col_name, res_col_name, res2_col_name=None):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe containing resume and job description data, and two or three strings containing the names of \n",
    "    columns found within the dataframe. \n",
    "    If two column names are given, make the third column name a None object. \n",
    "    ...\n",
    "    Find the similarity between the resume data and the job description data.\n",
    "    Return a list with the score of similarity between the resume data and the job data, and two generators containing\n",
    "    Doc objects with the natural-language-processed resume data and job data, respectivly\n",
    "    \"\"\"\n",
    "    skill_match = []\n",
    "    disabled = ['tokenizer', 'tagger', 'parser', 'lemmatizer', 'textcat', 'custom']\n",
    "\n",
    "    job_docs = create_docs(data, disabled, job_col_name)\n",
    "    res_docs = create_docs(data, disabled, res_col_name, res2_col_name)\n",
    "\n",
    "    for res_doc, job_doc in zip(res_docs, job_docs):\n",
    "        if (job_doc.text == '') or (res_doc.text == ''):\n",
    "            score = None\n",
    "        else:\n",
    "            score = res_doc.similarity(job_doc)\n",
    "        skill_match.append(score)\n",
    "\n",
    "    return skill_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b29c91e9-b6b3-47d4-ab76-c1a0b6b96fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_sq_err(compute, true):\n",
    "    \"\"\"\n",
    "    Takes in two lists containing computed values and true values respectivly, and computes the mean squared error.\n",
    "    If there is a missing value in either list, skip to the next computed value and true value \n",
    "    \"\"\"\n",
    "    MSE = 0\n",
    "    for i in range(min(len(compute), len(true))):\n",
    "        if (compute[i] is not None) and (true[i] is not None):\n",
    "            MSE += np.square(np.subtract(compute[i], true[i]))\n",
    "    \n",
    "    return (MSE / (i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6cb48f-4229-4502-b542-e26ea91378ab",
   "metadata": {},
   "source": [
    "### Research Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cf33191-6c7c-4e59-b722-04dcd025cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['skills_required', 'skills', 'related_skils_in_job', \n",
    "          'educationaL_requirements', 'degree_names', 'major_field_of_studies',\n",
    "         'responsibilities.1', 'responsibilities', None,\n",
    "         'job_position_name', 'positions', None]\n",
    "title = ['skills', 'degree', 'responsibilities', 'job position']\n",
    "\n",
    "match_score = resume_job_match['matched_score'].tolist()\n",
    "\n",
    "similarity = dict()\n",
    "for i in range(int(len(columns) / 3)):\n",
    "    sim = check_similarity(resume_job_match, columns[3*i], columns[3*i + 1], columns[3*i + 2])\n",
    "    MSE = mean_sq_err(sim, match_score)\n",
    "    similarity[title[i]] = MSE\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d52b9d-f4fe-48ae-a31d-9a93d498e972",
   "metadata": {},
   "source": [
    "To explain how these numbers are calculated, it's important to explain where this information comes from. USing skills as an example, I began with the data from *'resume_data.csv'*. I calculated the similarity between the skills the applicant had listed, the skills relevant to the job position the applicant worked previously, and the skills required by the job description. I combined the data provided by the applicant into a single string, and checked the similarity between the applicant's skills and the skills listed in the job description. A match between 0 and 1 is provided, with 1 being a perfect match, and 0 being completely unrelated. This is the computed match.\\\n",
    "For some categories, like the previous job positions held by the applicant, only one string is provided. As such, the computed value can take one or two strings of applicant information, depending on whether applicant information is stored in one or two places. \n",
    "From there, I computed the mean squared error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad33046f-f9ef-40bf-aea6-cd5d89f48e72",
   "metadata": {},
   "source": [
    "The mean squared error is computed between the match score provided by the dataset, and the computed values for each category of information. In this case, the mean squared error is used to indicate how heavily an ATS may weigh each section when calculating the match score. The larger the mean squared error, the less weight that section holds, and thus the less important it is to the ATS. Conversely, the smaller the mean squared error, the more important that section is. \n",
    "\n",
    "This is not a perfect estimate, by any means. In practice, an ATS would take the score provided for each category and compute the match score with different categories being weighted. For example, if the degree was less important than a candidate's previous job roles. However, we do not have the weights used to compute the provided match score. Further, when using several different categories of applicant information to evaluate, the data may heavily weight one particular category, but be much closer to several lesser weighted categories, and as such, mean squared error for each category would be high for the most heavily weighted, and much closer to the numerous lightly weighted categories. As such, discerning the category with the most importance placed upon from this information is tenuous at best, and outright wrong at worst.\n",
    "\n",
    "However, this information can tell us the best indicator for a match score. If the mean squared error between the skills scores is small, this can indicate that the similarity between an applicant's skills and the required skills is the best indicator for whether the match score will be high or low. This doesn't tell us the weights, but it does tell us the most likely outcome for a match. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c0fba54-a3bb-4b13-aa3b-b931fa06606f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared error of skills:  0.07175357068233537\n",
      "Mean Squared error of degree:  0.052926185909737425\n",
      "Mean Squared error of responsibilities:  0.14293504587083708\n",
      "Mean Squared error of job position:  0.10896527127001596\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(similarity)):\n",
    "    print(f\"Mean Squared error of {title[i]}: \", similarity[title[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33cd5e3-bc47-402b-9c67-09228e2ecea6",
   "metadata": {},
   "source": [
    "The category with the smallest mean squared error is degree. With a score of approximately $0.0529$, this is possibly due to the brevity that a list of applicant's degrees would naturally have a better match score with a smaller list of words to compare, but this is surprising to see. Generally, it would be expected that prior positions and work experience would overrule this, but it's certainly not unfeasible that an applicant who had the degree required for the position would be prioritized in comparison to an applicant lacking the necessary credentials. \n",
    "This means that an applicant's degree and level of education are the best indicator for whether or not that person is a good match for the job. \n",
    "\n",
    "Shortly after the job position category comes the skills category with approximately $0.0718$, and after that, the job position category with $0.109$. \n",
    "\n",
    "In contrast, the mean squared error of the responsibilities category, $0.143$ , indicates that the degree is the least important indicator of a good resume-job-description match. Similar to the degree category, this is surprising. It would go to show that a candidate with previous experience carrying out the same or similar tasks would be a better fit for a job, but this could very well be an incorrect assumption. Further, it's important to remember that the computer is simply matching words, and as such, lacks the ability to pick up on transferable skills, and further doesn't have the ability to ask the candidate to expand upon topics within a job interview.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc7f00-908a-4ab7-8924-cd5b59c917d3",
   "metadata": {},
   "source": [
    "### Research Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37af071e-7112-43cb-9e1c-57a1d92ffc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This retains the mean squared error of the original skills score\n",
    "MSE_skills = similarity[title[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60fd0dba-888a-47b1-9529-63e45d886ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym = ['machine learning', 'AI', 'neural network']\n",
    "synonym_df = []\n",
    "\n",
    "\n",
    "for i in range(len(synonym)):\n",
    "    df = resume_job_match[['skills', 'skills_required', 'related_skils_in_job']].copy()\n",
    "    df['skills'] = df['skills'].str.replace('Machine Learning', synonym[i])\n",
    "    df['skills'] = df['skills'].str.replace('ML', synonym[i])\n",
    "    \n",
    "    df['related_skils_in_job'] = df['related_skils_in_job'].str.replace('Machine Learning', synonym[i])\n",
    "    df['related_skils_in_job'] = df['related_skils_in_job'].str.replace('ML', synonym[i])\n",
    "    synonym_df.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7926a01-d8c4-49ff-92f0-2a898bab2bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_skills_compare = dict()\n",
    "for i in range(len(synonym_df)):\n",
    "    synonym_scores = check_similarity(synonym_df[i], 'skills', 'skills_required', 'related_skils_in_job')\n",
    "    MSE = mean_sq_err(synonym_scores, match_score)\n",
    "    synonym_skills_compare[synonym[i]] = MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7a778dc-f5c2-46a0-b048-7881b54b6b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error of 'Machine Learning' or  'ML':  0.07175357068233537\n",
      "Mean Squared Error of 'machine learning':  0.09826729516000227\n",
      "Mean Squared Error of 'AI':  0.09805075568555112\n",
      "Mean Squared Error of 'neural network':  0.09826118651859835\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error of \\'Machine Learning\\' or  \\'ML\\': \", MSE_skills)\n",
    "\n",
    "for i in range(len(synonym_skills_compare)):\n",
    "    print(f\"Mean Squared Error of \\'{synonym[i]}\\': \", synonym_skills_compare[synonym[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec005cac-9690-436d-b71e-19e719e6fb2d",
   "metadata": {},
   "source": [
    "This is the mean squared error for four different variations of the word \"Machine Learning\". This was carried out by finding every instance of the word \"Machine Learning\" or \"ML\" helps to see whether exact word matching has the same impact on word matching as synonyms. This tells us whether direct word matching works better, or whether synonyms work just as good. \n",
    "\n",
    "In this case, starting with the original dataset, we have the mean squared error, approximately $0.718$. For each instance of skills, each instance of \"Machine Learning\" and \"ML\" has been replaced with \"machine learning\" in all lowercase, \"AI\", or \"neural network\". These are not the same thing, but they are synonyms, and thus in testing out how closely related the mean squared error is, this can inform whether direct word matching is better than synonym matching for resume and job description checkers. \n",
    "\n",
    "In this case, all three examples of the synonyms had an increased mean squared error close to $0.098$, with an increase of just over $0.026$. This provides evidence to support that direct word matching would be the best way to go, rather than relying on synonyms or indirect word matches, as only the resumes were modified during this search. \n",
    "There is always the possibility the by changing to synonyms, thus leading to an increased match score, but given the regularity of increase, even when changing \"Machine Learning\" and \"ML\" to all lowercase, this indicates that any incidental increase is still heavily weighted out by the affects of indirect matching. \n",
    "\n",
    "Thus, it can be concluded that direct word matching when writing a resume is likely to be more effective at inciting a higher match score than using synonyms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e532654-7b84-4433-934c-9ca8e5541e5f",
   "metadata": {},
   "source": [
    "### Research Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0fcd42a-9bc3-4951-8aac-01f341d26053",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler = nlp.add_pipe(\"entity_ruler\", after=\"ner\")\n",
    "\n",
    "patterns = []\n",
    "with open('jz_skill_patterns.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        patterns.append(data)\n",
    "\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b5e4d8c-dc7f-4e45-9b2c-c84584a06b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(token: str, pattern: re.Pattern[str] = re.compile(r\"\\W+\")) -> str:\n",
    "    \"\"\"\n",
    "    Returns all the characters in the token lowercased and without matches to the\n",
    "    given pattern.\n",
    "\n",
    "    >>> clean(\"Hello!\")\n",
    "    'hello'\n",
    "    \"\"\"\n",
    "    return pattern.sub(\"\", token.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80c3656a-6a93-47e7-b3c5-aeafde074521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_compare(data, job_col_name, res_col_name, res2_col_name=None):\n",
    "    \"\"\"...\"\"\"\n",
    "    job_docs = create_docs(data, [], job_col_name)\n",
    "    res_docs = create_docs(data, [], res_col_name, res2_col_name)\n",
    "\n",
    "    job_skills = set()\n",
    "    res_skills = set()\n",
    "    match_per = []\n",
    "    \n",
    "    for res_doc, job_doc in zip(res_docs, job_docs):\n",
    "        total_matches = 0\n",
    "    \n",
    "        # If there are any skills listed in the job description, add them to a set \n",
    "        for ent in job_doc.ents:\n",
    "            job_skills.add(clean(ent.text))\n",
    "    \n",
    "        # If there are required skills, check the skills in the resume\n",
    "        # Otherwise, the number of matching skills is zero\n",
    "        if len(job_skills) > 0:\n",
    "            for ent in res_doc.ents:\n",
    "                res_skills.add(clean(ent.text))\n",
    "    \n",
    "        # If a skill in the job description is found in the resume, add one to total_matches \n",
    "        for skill in job_skills:\n",
    "            if skill in res_skills:\n",
    "                total_matches += 1\n",
    "                \n",
    "        if (len(job_skills) == 0):\n",
    "            # No skills required for job\n",
    "            match_per.append(None)\n",
    "        else:\n",
    "            match_per.append(total_matches / len(job_skills))\n",
    "\n",
    "    return match_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a697139-1a9f-4e55-a9a7-2a113d0c0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['skills_required', 'skills', 'related_skils_in_job', \n",
    "          'educationaL_requirements', 'degree_names', 'major_field_of_studies',\n",
    "         'responsibilities.1', 'responsibilities', None,\n",
    "         'job_position_name', 'positions', None]\n",
    "\n",
    "percentage = []\n",
    "\n",
    "for i in range(int(len(columns) / 3)):\n",
    "    percentage.append(keyword_compare(resume_job_match, columns[3*i], columns[3*i + 1], columns[3*i + 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9b339f-62fe-4221-9210-20f39a6c5494",
   "metadata": {},
   "source": [
    "Keyword selection, in this case, uses named entity recognition to pick out skills, organizations, and people. This may seem like a strange choice, and it certainly is an imperfect one, but further diving into the datasets provides answers as to why this choice was made. In particular, the jobzilla dataset used to identify skills is prioritized around identifying skills common in or adjacent to the tech industry, and thus skills like \"customer service\" are more difficult to identify. \n",
    "However, as we are measuring the percentage of the number of keywords in the job description being present in the resume and all keywords are being identified in the same manner, part of this discrepancy can be accounted for. If \"customer service\" cannot be identified by the keyword finder, it doesn't matter if it's present in the job description or the resume. Its presence or absence will not contribute to the match percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0daf2f5-6edf-4021-9f4c-07abaedcc69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared error of skills percentage:  0.10272318941134886\n",
      "Mean Squared error of skills similarity:  0.07175357068233537\n",
      "\n",
      "Mean Squared error of degree percentage:  0.1171220451174688\n",
      "Mean Squared error of degree similarity:  0.052926185909737425\n",
      "\n",
      "Mean Squared error of responsibilities percentage:  0.14293504587083708\n",
      "Mean Squared error of responsibilities similarity:  0.14293504587083708\n",
      "\n",
      "Mean Squared error of job position percentage:  0.1745173458103681\n",
      "Mean Squared error of job position similarity:  0.10896527127001596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title = ['skills', 'degree', 'responsibilities', 'job position']\n",
    "for i in range(len(percentage)):\n",
    "    MSE_per = mean_sq_err(percentage[i], match_score)\n",
    "    print(f\"Mean Squared error of {title[i]} percentage: \", MSE_per)\n",
    "    print(f\"Mean Squared error of {title[i]} similarity: \", similarity[title[i]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d057b1-8af5-4bfe-af4f-7583abed50fd",
   "metadata": {},
   "source": [
    "From the numbers computed, we can compare and see what way of reading resumes is better. Generally speaking, we can tell the mean squared error of keyword selecting is larger compared to the mean squared error using spacy's similarity function. This is likely due to the fact that spacy's similarity is Asofter on indirect matches, such as the difference between the phrases \"Neural Network\" and \"Machine Learning\". For spacy's similarity function, this would still produce a number indicating the closeness of each word, whereas the keyword matching would produce zero no matter what, since those words are not the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bf1e527-dbaa-4ea9-88e3-d1fcb51b2192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.39600063577922107\n"
     ]
    }
   ],
   "source": [
    "nlp1 = nlp(\"Neural Network\")\n",
    "nlp2 = nlp(\"Machine Learning\")\n",
    "\n",
    "print(nlp1.similarity(nlp1))\n",
    "print(nlp1.similarity(nlp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bf3cdb-1dcc-40a5-ba94-cc2dd3cb51f9",
   "metadata": {},
   "source": [
    "Ultimately, the answer of what gives the most accurate score goes to spacy's similarity function. The smaller mean squared error is a clear indicator that it's providing a better read across three of the four categories. The only exception to this was the responsibilities category, where both keyword matching and similarity produced the same result, approximately $0.1429$. This is bizarre, more so than if the keyword percentage was smaller than the similarity number. This could indicate that spacy's similarity function uses some of the same methods as the keyword method, such as utilizing a percentage. It could also be possible that the numbers are similar only when truncated, but given that both numbers go out to seventeen decimal places, the fact that both numbers have the same digits that far out is genuinely baffling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345fd7a0-fdd5-482f-88ad-c0c6dc25ec79",
   "metadata": {},
   "source": [
    "This also provides the answer to the final part of research question 3. Of the methods presented here, the most accurate scoring would be to use spacy's built in similarity function, though there is certainly room for improvement. \n",
    "\n",
    "Lastly, this helps support the second research question, albeit indirectly. When taking a holistic approach to ATS's in daily life, it's generally unknown what methods an ATS could be using, whether it be using an in-house similarity computation, an open-source option like spacy, or a more complicated AI reader. In any case, it stands to reason that all three options would find the best matches with direct word matching, rather than synonyms, even when synonyms are accounted for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b3957de-7724-43ad-b50c-b3aef5738f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "del resume_job_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "665f8c29-e6b4-4448-a491-085df1aff23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_data = pd.read_csv('test.csv') \n",
    "height, width = resume_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebb37321-a3cf-432a-be98-a771983ba4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data = pd.read_csv('jts.csv') \n",
    "job_short = job_data.head(height).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27bb086f-dfd4-4724-a490-e39f26287dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Category</th>\n",
       "      <th>id</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOCIAL MEDIA COMMUNICATIONS MANAGER Education ...</td>\n",
       "      <td>PUBLIC-RELATIONS</td>\n",
       "      <td>0</td>\n",
       "      <td>Flutter Developer</td>\n",
       "      <td>We are looking for hire experts flutter develo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEACHER Willing relocate: Anywhere Professiona...</td>\n",
       "      <td>TEACHER</td>\n",
       "      <td>1</td>\n",
       "      <td>Django Developer</td>\n",
       "      <td>PYTHON/DJANGO (Developer/Lead) - Job Code(PDJ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRINCIPAL CONSULTANT Executive Profile A dynam...</td>\n",
       "      <td>BANKING</td>\n",
       "      <td>2</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Data Scientist (Contractor)\\n\\nBangalore, IN\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SENIOR ASSOCIATE Executive Profile Seasoned Fi...</td>\n",
       "      <td>BANKING</td>\n",
       "      <td>3</td>\n",
       "      <td>iOS Developer</td>\n",
       "      <td>JOB DESCRIPTION:\\n\\nStrong framework outside o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACCOUNTANT Professional Summary I enthusiastic...</td>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>4</td>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>job responsibility full stack engineer – react...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>ENGINEERING OFFICER Objective Looking opportun...</td>\n",
       "      <td>ENGINEERING</td>\n",
       "      <td>507</td>\n",
       "      <td>Wordpress Developer</td>\n",
       "      <td>*Sr/Jr Wordpress Developer*\\n*Required skills ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>BUSINESS DEVELOPMENT MANAGER Summary Understan...</td>\n",
       "      <td>BUSINESS-DEVELOPMENT</td>\n",
       "      <td>508</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Business Title\\nMachine Learning Intern (Techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>HEAD GIRLS BASKETBALL COACH Summary Former col...</td>\n",
       "      <td>FITNESS</td>\n",
       "      <td>509</td>\n",
       "      <td>Network Administrator</td>\n",
       "      <td>Company description\\nARMSOFTECH.AIR provides s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>PRESIDENT Executive Profile Media relations pr...</td>\n",
       "      <td>PUBLIC-RELATIONS</td>\n",
       "      <td>510</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>About Us\\n\\nMorgan Stanley is a leading global...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>FINANCE DIRECTOR Executive Profile Dedicated a...</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>511</td>\n",
       "      <td>Django Developer</td>\n",
       "      <td>We are looking for a Python Developer to join ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Resume_str              Category  \\\n",
       "0    SOCIAL MEDIA COMMUNICATIONS MANAGER Education ...      PUBLIC-RELATIONS   \n",
       "1    TEACHER Willing relocate: Anywhere Professiona...               TEACHER   \n",
       "2    PRINCIPAL CONSULTANT Executive Profile A dynam...               BANKING   \n",
       "3    SENIOR ASSOCIATE Executive Profile Seasoned Fi...               BANKING   \n",
       "4    ACCOUNTANT Professional Summary I enthusiastic...            ACCOUNTANT   \n",
       "..                                                 ...                   ...   \n",
       "493  ENGINEERING OFFICER Objective Looking opportun...           ENGINEERING   \n",
       "494  BUSINESS DEVELOPMENT MANAGER Summary Understan...  BUSINESS-DEVELOPMENT   \n",
       "495  HEAD GIRLS BASKETBALL COACH Summary Former col...               FITNESS   \n",
       "496  PRESIDENT Executive Profile Media relations pr...      PUBLIC-RELATIONS   \n",
       "497  FINANCE DIRECTOR Executive Profile Dedicated a...               FINANCE   \n",
       "\n",
       "      id              Job Title  \\\n",
       "0      0      Flutter Developer   \n",
       "1      1       Django Developer   \n",
       "2      2       Machine Learning   \n",
       "3      3          iOS Developer   \n",
       "4      4   Full Stack Developer   \n",
       "..   ...                    ...   \n",
       "493  507    Wordpress Developer   \n",
       "494  508       Machine Learning   \n",
       "495  509  Network Administrator   \n",
       "496  510       Machine Learning   \n",
       "497  511       Django Developer   \n",
       "\n",
       "                                       Job Description  \n",
       "0    We are looking for hire experts flutter develo...  \n",
       "1    PYTHON/DJANGO (Developer/Lead) - Job Code(PDJ ...  \n",
       "2    Data Scientist (Contractor)\\n\\nBangalore, IN\\n...  \n",
       "3    JOB DESCRIPTION:\\n\\nStrong framework outside o...  \n",
       "4    job responsibility full stack engineer – react...  \n",
       "..                                                 ...  \n",
       "493  *Sr/Jr Wordpress Developer*\\n*Required skills ...  \n",
       "494  Business Title\\nMachine Learning Intern (Techn...  \n",
       "495  Company description\\nARMSOFTECH.AIR provides s...  \n",
       "496  About Us\\n\\nMorgan Stanley is a leading global...  \n",
       "497  We are looking for a Python Developer to join ...  \n",
       "\n",
       "[498 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match2 = pd.concat([resume_data, job_short], axis=1)\n",
    "del job_data\n",
    "del job_short\n",
    "del resume_data\n",
    "match2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb315b-34b2-4a19-8a67-7b8f96c24754",
   "metadata": {},
   "source": [
    "## Implications and Limitations\n",
    "\n",
    "A wide variety of people would benefit from utilizing this analysis, including job applicants, recruiters, HR personnel, or anyone wishing to build their own ATS. Ultimately, it's an introductory step into the variety of applicant tracking systems. It provides some information on how they can be best utilized, and given the growing number of companies using them, it's especially unlikely that they're going away. Indeed, for many reading this, it's especially likely that their resumes will be graded by an ATS. Knowing how they work and how to structure a resume so that it's both human and machine readable is an important skill to have. \n",
    "\n",
    "However, it would be remiss to talk about how ATS's work, and not talk about how they, like all projects that rely on data, are only as good as the data they're given. When talking about employment especially, there is plenty of discrimination that shows up in hiring records, and even attempts to mitigate bias can still yield pitiful results. One especially notable example of this was Amazon's AI recruiting tool was found to be biased against hiring women, and was found to systematically discriminate against people using the word \"women\" within their resume. Even when the word \"women\" was explicitly removed from consideration, the tool still suffered from bias problems, and was ultimately scrapped. In fact, this plays into one of the limitations of this tool. Despite the fact that names, genders, and ages are not included within the datasets, things like extracurricular activities, what college someone attended, where they worked previously, or even how they phrase skills, responsibilities, or accomplishments can be used to extrapolate identifying information, and given that this dataset does not include this information, it's difficult to tell where bias is being reinforced. \n",
    "\n",
    "Another limitation of this project was that it was built using imperfect data. In particular, despite having a large number of records, the skills dataset in particular was preferential to include terms common in the tech industry, rather than having a balanced variety of terms. The fact that changing certain terms still leads to significant changes in the data does indicate the relevance of the terms, but the noticeable prevalence does indicate that the data is not necessarily the most reliable. \n",
    "\n",
    "Lastly, while this covered two potential ways an ATS may work, ATS's vary widely depending on whose programming them, or how they're programmed to run. One of the most common ways is to utilize machine learning to measure the similarity between a resume and a job description, and is an aspect left uncovered by this project. Ultimately, this was decided due to debugging constraints, and learning to integrate natural language processing into neural networks was a topic deserving of its own deep dive, so for ease, this was scrapped from this project. However, this is leaving out one of the most common elements in an ATS out of a project specifically about exploring them. \n",
    "\n",
    "Ultimately, this is one source of information on a varied and complex topic, and should be treated as such. Like any good researcher, to find out more, getting information from multiple sources is important to reaching a well-rounded understanding. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
